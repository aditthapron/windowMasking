Params:
--model SincNet --w_len 500 --sampling False --mask hamming --hard_mask True --penalty 0.1 --seed 1
/home/aditthapron/work/[/home/aditthapron/work/anaconda3/envs/torch_1_12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/aditthapron/work/[/home/aditthapron/work/anaconda3/envs/torch_1_12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/aditthapron/work/[/home/aditthapron/work/anaconda3/envs/torch_1_12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/aditthapron/work/[/home/aditthapron/work/anaconda3/envs/torch_1_12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/aditthapron/work/[/home/aditthapron/work/anaconda3/envs/torch_1_12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/aditthapron/work/[/home/aditthapron/work/anaconda3/envs/torch_1_12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
SincNet_TIMIT_500_10_hamming_True__0.1_1 -- 2022-10-27_11:31:49
Valid: 0, loss=3.712, err=0.800, err_snt=0.334, tr_loss=2.761, tr_err=0.675, length=3959.0, sr=8000.0
Valid: 1, loss=3.195, err=0.660, err_snt=0.120, tr_loss=1.391, tr_err=0.366, length=3845.6, sr=8000.0
Valid: 2, loss=3.243, err=0.643, err_snt=0.085, tr_loss=1.074, tr_err=0.293, length=3239.0, sr=8000.0
Valid: 3, loss=3.104, err=0.579, err_snt=0.041, tr_loss=0.578, tr_err=0.164, length=3628.8, sr=8000.0
Valid: 4, loss=3.298, err=0.565, err_snt=0.045, tr_loss=0.373, tr_err=0.106, length=3624.3, sr=8000.0
Valid: 5, loss=3.287, err=0.542, err_snt=0.027, tr_loss=0.266, tr_err=0.076, length=3620.7, sr=8000.0
Valid: 6, loss=3.421, err=0.555, err_snt=0.032, tr_loss=0.245, tr_err=0.071, length=3113.7, sr=8000.0
Valid: 7, loss=3.559, err=0.544, err_snt=0.032, tr_loss=0.197, tr_err=0.060, length=2811.3, sr=8000.0
Valid: 8, loss=3.620, err=0.527, err_snt=0.030, tr_loss=0.144, tr_err=0.045, length=2504.7, sr=8000.0
Valid: 9, loss=3.750, err=0.529, err_snt=0.025, tr_loss=0.147, tr_err=0.045, length=3002.5, sr=8000.0
Valid: 10, loss=3.926, err=0.535, err_snt=0.032, tr_loss=0.128, tr_err=0.039, length=2895.9, sr=8000.0
Valid: 11, loss=3.910, err=0.522, err_snt=0.019, tr_loss=0.124, tr_err=0.036, length=2893.1, sr=8000.0
Valid: 12, loss=4.031, err=0.520, err_snt=0.019, tr_loss=0.102, tr_err=0.031, length=3090.7, sr=8000.0
Valid: 13, loss=4.135, err=0.525, err_snt=0.030, tr_loss=0.095, tr_err=0.028, length=3190.1, sr=8000.0
Valid: 14, loss=4.030, err=0.486, err_snt=0.022, tr_loss=0.097, tr_err=0.031, length=2987.1, sr=8000.0
Valid: 15, loss=4.200, err=0.491, err_snt=0.021, tr_loss=0.098, tr_err=0.031, length=2883.1, sr=8000.0
Valid: 16, loss=4.188, err=0.473, err_snt=0.019, tr_loss=0.083, tr_err=0.027, length=2881.1, sr=8000.0
Valid: 17, loss=4.364, err=0.468, err_snt=0.027, tr_loss=0.073, tr_err=0.022, length=2776.7, sr=8000.0
Valid: 18, loss=4.284, err=0.477, err_snt=0.019, tr_loss=0.064, tr_err=0.019, length=2768.7, sr=8000.0
Valid: 19, loss=4.403, err=0.486, err_snt=0.026, tr_loss=0.073, tr_err=0.022, length=2767.1, sr=8000.0
Valid: 20, loss=4.387, err=0.475, err_snt=0.026, tr_loss=0.053, tr_err=0.017, length=2764.4, sr=8000.0
Valid: 21, loss=4.301, err=0.484, err_snt=0.018, tr_loss=0.059, tr_err=0.017, length=2757.9, sr=8000.0
Valid: 22, loss=4.516, err=0.475, err_snt=0.027, tr_loss=0.058, tr_err=0.017, length=2756.2, sr=8000.0
Valid: 23, loss=4.546, err=0.514, err_snt=0.016, tr_loss=0.052, tr_err=0.017, length=2753.4, sr=8000.0
Valid: 24, loss=4.498, err=0.507, err_snt=0.023, tr_loss=0.043, tr_err=0.014, length=3047.6, sr=8000.0
Valid: 25, loss=4.657, err=0.484, err_snt=0.021, tr_loss=0.051, tr_err=0.015, length=3046.6, sr=8000.0
Valid: 26, loss=4.522, err=0.480, err_snt=0.021, tr_loss=0.042, tr_err=0.014, length=3040.4, sr=8000.0
Valid: 27, loss=4.544, err=0.505, err_snt=0.018, tr_loss=0.049, tr_err=0.015, length=3138.9, sr=8000.0
Valid: 28, loss=4.583, err=0.513, err_snt=0.019, tr_loss=0.046, tr_err=0.014, length=2934.4, sr=8000.0
Valid: 29, loss=4.713, err=0.508, err_snt=0.017, tr_loss=0.044, tr_err=0.013, length=2925.7, sr=8000.0
Valid: 30, loss=4.648, err=0.498, err_snt=0.014, tr_loss=0.045, tr_err=0.015, length=2814.7, sr=8000.0
Valid: 31, loss=4.777, err=0.503, err_snt=0.014, tr_loss=0.036, tr_err=0.012, length=2813.7, sr=8000.0
Valid: 32, loss=4.737, err=0.508, err_snt=0.019, tr_loss=0.044, tr_err=0.012, length=2813.2, sr=8000.0
Valid: 33, loss=4.729, err=0.491, err_snt=0.014, tr_loss=0.035, tr_err=0.011, length=2810.1, sr=8000.0
Valid: 34, loss=4.791, err=0.504, err_snt=0.014, tr_loss=0.036, tr_err=0.011, length=2607.1, sr=8000.0
Valid: 35, loss=4.820, err=0.506, err_snt=0.017, tr_loss=0.040, tr_err=0.013, length=2598.6, sr=8000.0
Valid: 36, loss=4.725, err=0.483, err_snt=0.013, tr_loss=0.035, tr_err=0.011, length=2496.2, sr=8000.0
Valid: 37, loss=4.860, err=0.510, err_snt=0.019, tr_loss=0.036, tr_err=0.011, length=2287.9, sr=8000.0
Valid: 38, loss=4.906, err=0.506, err_snt=0.019, tr_loss=0.038, tr_err=0.011, length=2182.7, sr=8000.0
Valid: 39, loss=4.843, err=0.510, err_snt=0.018, tr_loss=0.037, tr_err=0.011, length=2180.3, sr=8000.0
Valid: 40, loss=4.821, err=0.505, err_snt=0.013, tr_loss=0.034, tr_err=0.010, length=1972.9, sr=8000.0
Valid: 41, loss=4.961, err=0.507, err_snt=0.014, tr_loss=0.034, tr_err=0.010, length=1961.3, sr=8000.0
Valid: 42, loss=4.855, err=0.502, err_snt=0.020, tr_loss=0.027, tr_err=0.009, length=2055.3, sr=8000.0
Valid: 43, loss=4.891, err=0.503, err_snt=0.016, tr_loss=0.027, tr_err=0.009, length=2245.5, sr=8000.0
Valid: 44, loss=5.029, err=0.511, err_snt=0.014, tr_loss=0.030, tr_err=0.010, length=2041.2, sr=8000.0
Valid: 45, loss=5.124, err=0.512, err_snt=0.015, tr_loss=0.031, tr_err=0.010, length=1935.6, sr=8000.0
Valid: 46, loss=4.886, err=0.480, err_snt=0.014, tr_loss=0.028, tr_err=0.009, length=2019.4, sr=8000.0
Valid: 47, loss=4.990, err=0.496, err_snt=0.017, tr_loss=0.033, tr_err=0.011, length=2017.3, sr=8000.0
Valid: 48, loss=5.060, err=0.506, err_snt=0.014, tr_loss=0.028, tr_err=0.008, length=2107.5, sr=8000.0
Valid: 49, loss=5.027, err=0.505, err_snt=0.012, tr_loss=0.034, tr_err=0.010, length=2000.3, sr=8000.0
Valid: 50, loss=5.045, err=0.501, err_snt=0.013, tr_loss=0.028, tr_err=0.009, length=2096.3, sr=8000.0
Valid: 51, loss=5.206, err=0.514, err_snt=0.017, tr_loss=0.027, tr_err=0.008, length=2086.8, sr=8000.0
Valid: 52, loss=5.110, err=0.508, err_snt=0.024, tr_loss=0.031, tr_err=0.010, length=1979.8, sr=8000.0
Valid: 53, loss=5.229, err=0.512, err_snt=0.020, tr_loss=0.032, tr_err=0.009, length=1966.8, sr=8000.0
Valid: 54, loss=5.104, err=0.503, err_snt=0.014, tr_loss=0.026, tr_err=0.007, length=1962.4, sr=8000.0
Valid: 55, loss=5.127, err=0.483, err_snt=0.018, tr_loss=0.025, tr_err=0.007, length=1937.1, sr=8000.0
Valid: 56, loss=5.191, err=0.488, err_snt=0.018, tr_loss=0.026, tr_err=0.008, length=1923.0, sr=8000.0
Valid: 57, loss=5.746, err=0.530, err_snt=0.018, tr_loss=0.077, tr_err=0.023, length=1918.8, sr=8000.0
Valid: 58, loss=5.253, err=0.515, err_snt=0.015, tr_loss=0.029, tr_err=0.009, length=1914.2, sr=8000.0
Valid: 59, loss=5.192, err=0.505, err_snt=0.016, tr_loss=0.027, tr_err=0.008, length=2112.9, sr=8000.0
Valid: 60, loss=5.258, err=0.506, err_snt=0.012, tr_loss=0.025, tr_err=0.009, length=2095.3, sr=8000.0
Valid: 61, loss=5.289, err=0.515, err_snt=0.011, tr_loss=0.034, tr_err=0.010, length=1983.2, sr=8000.0
Valid: 62, loss=5.234, err=0.512, err_snt=0.010, tr_loss=0.025, tr_err=0.008, length=1979.0, sr=8000.0
Valid: 63, loss=5.340, err=0.516, err_snt=0.011, tr_loss=0.031, tr_err=0.009, length=1951.6, sr=8000.0
Valid: 64, loss=5.326, err=0.515, err_snt=0.012, tr_loss=0.035, tr_err=0.010, length=1943.3, sr=8000.0
Valid: 65, loss=5.124, err=0.499, err_snt=0.012, tr_loss=0.022, tr_err=0.008, length=1938.1, sr=8000.0
Valid: 66, loss=5.262, err=0.480, err_snt=0.018, tr_loss=0.027, tr_err=0.009, length=1918.7, sr=8000.0
Valid: 67, loss=5.346, err=0.498, err_snt=0.016, tr_loss=0.037, tr_err=0.011, length=1993.6, sr=8000.0
Valid: 68, loss=5.661, err=0.532, err_snt=0.013, tr_loss=0.055, tr_err=0.016, length=1979.9, sr=8000.0
Valid: 69, loss=5.318, err=0.515, err_snt=0.014, tr_loss=0.032, tr_err=0.010, length=1949.7, sr=8000.0
Valid: 70, loss=5.321, err=0.522, err_snt=0.014, tr_loss=0.030, tr_err=0.009, length=2048.1, sr=8000.0
Valid: 71, loss=5.249, err=0.516, err_snt=0.014, tr_loss=0.030, tr_err=0.009, length=1944.7, sr=8000.0
Valid: 72, loss=5.874, err=0.511, err_snt=0.014, tr_loss=0.029, tr_err=0.009, length=1841.2, sr=8000.0
Valid: 73, loss=5.907, err=0.524, err_snt=0.013, tr_loss=0.033, tr_err=0.010, length=1812.1, sr=8000.0
Valid: 74, loss=5.659, err=0.543, err_snt=0.012, tr_loss=0.039, tr_err=0.012, length=1805.6, sr=8000.0
Valid: 75, loss=5.542, err=0.497, err_snt=0.013, tr_loss=0.042, tr_err=0.011, length=1993.5, sr=8000.0
Valid: 76, loss=5.340, err=0.488, err_snt=0.013, tr_loss=0.032, tr_err=0.011, length=1983.5, sr=8000.0
Valid: 77, loss=5.411, err=0.523, err_snt=0.012, tr_loss=0.039, tr_err=0.012, length=1949.7, sr=8000.0
Valid: 78, loss=5.316, err=0.519, err_snt=0.014, tr_loss=0.041, tr_err=0.013, length=1911.7, sr=8000.0
Valid: 79, loss=5.368, err=0.520, err_snt=0.012, tr_loss=0.038, tr_err=0.011, length=1899.5, sr=8000.0
Valid: 80, loss=5.399, err=0.527, err_snt=0.014, tr_loss=0.051, tr_err=0.015, length=1993.6, sr=8000.0
Valid: 81, loss=5.374, err=0.523, err_snt=0.015, tr_loss=0.034, tr_err=0.011, length=2089.7, sr=8000.0
Valid: 82, loss=5.382, err=0.527, err_snt=0.012, tr_loss=0.031, tr_err=0.010, length=1964.6, sr=8000.0
Valid: 83, loss=5.394, err=0.529, err_snt=0.014, tr_loss=0.040, tr_err=0.012, length=1915.5, sr=8000.0
Valid: 84, loss=5.467, err=0.535, err_snt=0.011, tr_loss=0.062, tr_err=0.018, length=2092.4, sr=8000.0
Valid: 85, loss=5.286, err=0.534, err_snt=0.014, tr_loss=0.045, tr_err=0.013, length=1951.6, sr=8000.0
Valid: 86, loss=5.244, err=0.535, err_snt=0.011, tr_loss=0.046, tr_err=0.015, length=1990.1, sr=8000.0
Valid: 87, loss=5.256, err=0.540, err_snt=0.014, tr_loss=0.042, tr_err=0.013, length=1915.6, sr=8000.0
Valid: 88, loss=5.554, err=0.551, err_snt=0.021, tr_loss=0.075, tr_err=0.020, length=1938.2, sr=8000.0
Valid: 89, loss=5.374, err=0.548, err_snt=0.014, tr_loss=0.067, tr_err=0.019, length=1978.2, sr=8000.0
Valid: 90, loss=5.234, err=0.544, err_snt=0.016, tr_loss=0.046, tr_err=0.014, length=1969.3, sr=8000.0
Valid: 91, loss=5.411, err=0.552, err_snt=0.016, tr_loss=0.072, tr_err=0.021, length=2205.6, sr=8000.0
Valid: 92, loss=5.337, err=0.516, err_snt=0.012, tr_loss=0.058, tr_err=0.018, length=2199.2, sr=8000.0
Valid: 93, loss=5.240, err=0.527, err_snt=0.012, tr_loss=0.052, tr_err=0.016, length=2164.8, sr=8000.0
Valid: 94, loss=5.481, err=0.514, err_snt=0.013, tr_loss=0.073, tr_err=0.020, length=2151.0, sr=8000.0
Valid: 95, loss=5.441, err=0.539, err_snt=0.012, tr_loss=0.088, tr_err=0.025, length=2185.9, sr=8000.0
Valid: 96, loss=5.346, err=0.515, err_snt=0.009, tr_loss=0.077, tr_err=0.022, length=2143.2, sr=8000.0
Valid: 97, loss=5.390, err=0.524, err_snt=0.015, tr_loss=0.061, tr_err=0.018, length=2072.1, sr=8000.0
Valid: 98, loss=5.408, err=0.524, err_snt=0.011, tr_loss=0.099, tr_err=0.028, length=2075.9, sr=8000.0
Valid: 99, loss=5.356, err=0.523, err_snt=0.018, tr_loss=0.078, tr_err=0.023, length=2070.6, sr=8000.0
Valid: 100, loss=5.321, err=0.567, err_snt=0.014, tr_loss=0.092, tr_err=0.025, length=1913.6, sr=8000.0
Valid: 101, loss=5.337, err=0.572, err_snt=0.013, tr_loss=0.118, tr_err=0.033, length=1962.6, sr=8000.0
Valid: 102, loss=5.334, err=0.580, err_snt=0.009, tr_loss=0.140, tr_err=0.037, length=1839.4, sr=8000.0
Valid: 103, loss=5.229, err=0.583, err_snt=0.012, tr_loss=0.141, tr_err=0.141, length=1793.2, sr=8000.0
Valid: 104, loss=5.375, err=0.597, err_snt=0.012, tr_loss=0.236, tr_err=0.066, length=1629.7, sr=8000.0
Valid: 105, loss=5.112, err=0.594, err_snt=0.011, tr_loss=0.229, tr_err=0.063, length=1654.9, sr=8000.0
Valid: 106, loss=4.942, err=0.593, err_snt=0.009, tr_loss=0.210, tr_err=0.056, length=1535.8, sr=8000.0
Valid: 107, loss=5.181, err=0.594, err_snt=0.010, tr_loss=0.162, tr_err=0.146, length=1532.5, sr=8000.0
Valid: 108, loss=5.103, err=0.597, err_snt=0.010, tr_loss=0.187, tr_err=0.051, length=1588.1, sr=8000.0
Valid: 109, loss=4.918, err=0.600, err_snt=0.010, tr_loss=0.258, tr_err=0.071, length=1525.8, sr=8000.0
Valid: 110, loss=5.022, err=0.594, err_snt=0.011, tr_loss=0.176, tr_err=0.149, length=1524.5, sr=8000.0
Valid: 111, loss=4.835, err=0.601, err_snt=0.010, tr_loss=0.220, tr_err=0.061, length=1484.3, sr=8000.0
Valid: 112, loss=4.496, err=0.622, err_snt=0.009, tr_loss=0.433, tr_err=0.118, length=1523.0, sr=8000.0
Valid: 113, loss=4.475, err=0.652, err_snt=0.017, tr_loss=0.678, tr_err=0.183, length=1461.1, sr=8000.0
Valid: 114, loss=4.626, err=0.648, err_snt=0.014, tr_loss=0.607, tr_err=0.165, length=1580.6, sr=8000.0
Valid: 115, loss=4.598, err=0.628, err_snt=0.012, tr_loss=0.398, tr_err=0.106, length=1500.8, sr=8000.0
Valid: 116, loss=4.683, err=0.628, err_snt=0.010, tr_loss=0.409, tr_err=0.104, length=1633.6, sr=8000.0
Valid: 117, loss=4.767, err=0.633, err_snt=0.010, tr_loss=0.469, tr_err=0.121, length=1697.3, sr=8000.0
Valid: 118, loss=4.767, err=0.630, err_snt=0.009, tr_loss=0.397, tr_err=0.103, length=1630.8, sr=8000.0
Valid: 119, loss=4.791, err=0.631, err_snt=0.009, tr_loss=0.426, tr_err=0.108, length=1583.7, sr=8000.0
Average time per step: 0.0469532493046875
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
MACS: 13140576.0, Params: 54408.0
